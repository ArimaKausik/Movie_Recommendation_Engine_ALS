{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('movie-ALS-val').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sparkContext.textFile('file:///d:/sparkcourse/Recommendation-movies/ml-100k/u.data').map(lambda x : x.split()).map(lambda x: (int(x[0]),int(x[1]),int(x[2]),int(x[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.toDF(['user','movie','rating','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+---------+\n",
      "|user|movie|rating|timestamp|\n",
      "+----+-----+------+---------+\n",
      "| 196|  242|     3|881250949|\n",
      "| 186|  302|     3|891717742|\n",
      "|  22|  377|     1|878887116|\n",
      "| 244|   51|     2|880606923|\n",
      "| 166|  346|     1|886397596|\n",
      "| 298|  474|     4|884182806|\n",
      "| 115|  265|     2|881171488|\n",
      "| 253|  465|     5|891628467|\n",
      "| 305|  451|     3|886324817|\n",
      "|   6|   86|     3|883603013|\n",
      "|  62|  257|     2|879372434|\n",
      "| 286| 1014|     5|879781125|\n",
      "| 200|  222|     5|876042340|\n",
      "| 210|   40|     3|891035994|\n",
      "| 224|   29|     3|888104457|\n",
      "| 303|  785|     3|879485318|\n",
      "| 122|  387|     5|879270459|\n",
      "| 194|  274|     2|879539794|\n",
      "| 291| 1042|     4|874834944|\n",
      "| 234| 1184|     2|892079237|\n",
      "+----+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit(df,time):\n",
    "    test = df.select('*').where(col('timestamp')>time)\n",
    "    train = df.select('*').where(col('timestamp')<=time)\n",
    "    return(train.drop(col('timestamp')).cache(),test.drop(col('timestamp')).cache())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainLength 82281 | TestLength 17719\n"
     ]
    }
   ],
   "source": [
    "trainDf,testDf = trainTestSplit(df,890000000) #Set above 15 Mar 1998 as test set and those before as train set\n",
    "print('TrainLength '+str(trainDf.count())+' | TestLength '+str(testDf.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "from pyspark.ml.evaluation import RankingEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineRddsForRankingMeasure(predDf):\n",
    "    pred = predDf.select('user','movie').orderBy(col('prediction').desc())\n",
    "    act = predDf.select('user','movie').orderBy(col('rating').desc()).where(col('rating')>=3)#Act thres for good ratings\n",
    "    predRdd = pred.rdd.map(tuple).groupByKey().mapValues(list)\n",
    "    actRdd = act.rdd.map(tuple).groupByKey().mapValues(list)\n",
    "    predAct = predRdd.leftOuterJoin(actRdd)\n",
    "    return(predAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def changeToDf(predActRdd):\n",
    "#    user = predActRdd[0]\n",
    "#    items = predActRdd[1]\n",
    "#    df = (user,items[0],items[1]).toDF(['user','prediction','actual'])\n",
    "#    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropKey(data):\n",
    "    predAct = data[1]\n",
    "    return(predAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestFitRank(itera,rankArray,trainDf):\n",
    "    highPrec = 0\n",
    "    flagRank = 0\n",
    "    for rank in rankArray:\n",
    "        als = ALS(maxIter=itera,regParam=0.01,rank=rank,implicitPrefs=False,userCol=\"user\",itemCol=\"movie\",ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "        trainSplit,valSplit = trainDf.randomSplit([0.9,0.1])\n",
    "        model = als.fit(trainSplit)\n",
    "        pred = model.transform(valSplit)\n",
    "        predTrans = combineRddsForRankingMeasure(pred)\n",
    "        predAndAct = predTrans.map(lambda x: x[1]).filter(lambda x: x[1] != None)\n",
    "        metrics = RankingMetrics(predAndAct)\n",
    "        precision = metrics.precisionAt(10)\n",
    "        if(precision>highPrec):\n",
    "            highPrec = precision\n",
    "            flagRank = rank\n",
    "    return(highPrec,flagRank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxIter(rank,iterArray,trainDf):\n",
    "    highPrec = 0\n",
    "    flagIter = 0\n",
    "    for itera in iterArray:\n",
    "        als = ALS(maxIter=itera,regParam=0.01,rank=rank,implicitPrefs=False,userCol=\"user\",itemCol=\"movie\",ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "        trainSplit,valSplit = trainDf.randomSplit([0.9,0.1])\n",
    "        model = als.fit(trainSplit)\n",
    "        pred = model.transform(valSplit)\n",
    "        predTrans = combineRddsForRankingMeasure(pred)\n",
    "        predAndAct = predTrans.map(lambda x: x[1]).filter(lambda x: x[1] != None)\n",
    "        metrics = RankingMetrics(predAndAct)\n",
    "        precision = metrics.precisionAt(10)\n",
    "        if(precision>highPrec):\n",
    "            highPrec = precision\n",
    "            flagIter = itera\n",
    "    return(highPrec,flagIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,rank = findBestFitRank(11,[4,6,8],trainDf) #Tuning rank hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Score 0.595838926174497 | Best_Rank 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Best_Score \"+str(score)+\" | Best_Rank \"+str(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,itera = findMaxIter(8,[9,11,13],trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Score 0.6079019073569478 | Best_Iter 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Best_Score \"+str(score)+\" | Best_Iter \"+str(itera)) #Tuning iteration hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(df):\n",
    "    als = ALS(maxIter = 11, rank =8, regParam = 0.01, implicitPrefs = False, userCol = \"user\", itemCol = \"movie\", ratingCol = \"rating\",coldStartStrategy=\"drop\")\n",
    "    model = als.fit(df)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testError(df,alsModel):\n",
    "    predDf = alsModel.transform(df)\n",
    "    testRdd = combineRddsForRankingMeasure(predDf)\n",
    "    predAndAct = testRdd.map(lambda x: x[1]).filter(lambda x: x[1] != None)\n",
    "    metrics = RankingMetrics(predAndAct)\n",
    "    precision = metrics.precisionAt(10)\n",
    "    MAP = metrics.meanAveragePrecision\n",
    "    ndcg = metrics.ndcgAt(10)\n",
    "    print(\"Precision at 10 - \"+str(precision))\n",
    "    print(\"MAP - \"+str(MAP))\n",
    "    print(\"ndcg - \"+str(ndcg))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at 10 - 0.5555555555555555\n",
      "MAP - 0.906664292842798\n",
      "ndcg - 0.9311795896162314\n"
     ]
    }
   ],
   "source": [
    "rankingMeasure = testError(testDf,model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nameDict():\n",
    "    movieName = {}\n",
    "    with open(\"d:/sparkcourse/Recommendation-movies/ml-100k/u.ITEM\") as doc:\n",
    "        for line in doc:\n",
    "            fields = line.split('|')\n",
    "            movieName[int(fields[0])] = fields[1]\n",
    "    return(movieName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bMovieName = spark.sparkContext.broadcast(nameDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendations\n",
    "def userRecommendation(userID,model,count):\n",
    "    userRecs = model.recommendForAllUsers(count)\n",
    "    reco = userRecs.where(userRecs.user == userID).select(\"recommendations.movie\").collect()\n",
    "    for i in reco:\n",
    "        for j in i[0]:\n",
    "            print(bMovieName.value[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspector General, The (1949)\n",
      "Chungking Express (1994)\n",
      "Faust (1994)\n",
      "Little Princess, The (1939)\n",
      "Meet John Doe (1941)\n",
      "Jean de Florette (1986)\n",
      "Aparajito (1956)\n",
      "Old Man and the Sea, The (1958)\n",
      "NÃ©nette et Boni (1996)\n",
      "Close Shave, A (1995)\n"
     ]
    }
   ],
   "source": [
    "userID = 62\n",
    "userRecommendation(userID,model,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
